{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import preprocessing as pre\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train_pd = pd.read_csv(\"/Users/soonam/Desktop/HKUST/Courses/MSBD5001/Project/Kaggle/train.csv\")\n",
    "test_pd = pd.read_csv(\"/Users/soonam/Desktop/HKUST/Courses/MSBD5001/Project/Kaggle/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                        int64\n",
       "penalty                  object\n",
       "l1_ratio                float64\n",
       "alpha                   float64\n",
       "max_iter                  int64\n",
       "random_state              int64\n",
       "n_jobs                    int64\n",
       "n_samples                 int64\n",
       "n_features                int64\n",
       "n_classes                 int64\n",
       "n_clusters_per_class      int64\n",
       "n_informative             int64\n",
       "flip_y                  float64\n",
       "scale                   float64\n",
       "time                    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_pd.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select columns\n",
    "X_before_train = train_pd_encoded.drop(['id','time'],axis=1)\n",
    "y_before_train = train_pd_encoded['time']\n",
    "\n",
    "x_to_be_preicted = test_pd_encoded.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering..\n",
    "#Hot encoding for  penalty column\n",
    "#train_pd.penalty.unique();\n",
    "#one hot encoding\n",
    "#training data\n",
    "train_pd_encoded = pd.get_dummies(train_pd, columns=['penalty'])\n",
    "#train_pd_encoded['n_features'] = train_pd_encoded.n_features.astype('category')\n",
    "#train_pd_encoded['n_classes'] = train_pd_encoded.n_classes.astype('category')\n",
    "train_pd_encoded['n_clusters_per_class'] = train_pd_encoded.n_clusters_per_class.astype('category')\n",
    "train_pd_encoded['n_informative'] = train_pd_encoded.n_informative.astype('category')\n",
    "train_pd_encoded['n_jobs'] = train_pd_encoded.n_jobs.astype('category')\n",
    "#train_pd_encoded['alpha'] = train_pd_encoded.alpha.astype('category')\n",
    "train_pd_encoded['n_samples'] = train_pd_encoded.n_samples.astype('category')\n",
    "\n",
    "#change datatype\n",
    "train_pd_encoded['max_iter'] = train_pd_encoded.max_iter.astype(float)\n",
    "train_pd_encoded['random_state'] = train_pd_encoded.random_state.astype(float)\n",
    "#train_pd_encoded['n_jobs'] = train_pd_encoded.n_jobs.astype(float)\n",
    "#train_pd_encoded['n_samples'] = train_pd_encoded.n_samples.astype(float)\n",
    "train_pd_encoded['n_features'] = train_pd_encoded.n_features.astype(float)\n",
    "train_pd_encoded['n_classes'] = train_pd_encoded.n_classes.astype(float)\n",
    "#train_pd_encoded['n_informative'] = train_pd_encoded.n_informative.astype(float)\n",
    "\n",
    "\n",
    "#testing data\n",
    "test_pd_encoded = pd.get_dummies(test_pd, columns=['penalty'])\n",
    "#test_pd_encoded['n_features'] = test_pd_encoded.n_features.astype('category')\n",
    "#test_pd_encoded['n_classes'] = test_pd_encoded.n_classes.astype('category')\n",
    "test_pd_encoded['n_clusters_per_class'] = test_pd_encoded.n_clusters_per_class.astype('category')\n",
    "test_pd_encoded['n_informative'] = test_pd_encoded.n_informative.astype('category')\n",
    "test_pd_encoded['n_jobs'] = test_pd_encoded.n_jobs.astype('category')\n",
    "#test_pd_encoded['alpha'] = test_pd_encoded.alpha.astype('category')\n",
    "test_pd_encoded['n_samples'] = test_pd_encoded.n_samples.astype('category')\n",
    "\n",
    "test_pd_encoded['max_iter'] = test_pd_encoded.max_iter.astype(float)\n",
    "test_pd_encoded['random_state'] = test_pd_encoded.random_state.astype(float)\n",
    "#test_pd_encoded['n_jobs'] = test_pd_encoded.n_jobs.astype(float)\n",
    "#test_pd_encoded['n_samples'] = test_pd_encoded.n_samples.astype(float)\n",
    "test_pd_encoded['n_features'] = test_pd_encoded.n_features.astype(float)\n",
    "test_pd_encoded['n_classes'] = test_pd_encoded.n_classes.astype(float)\n",
    "#test_pd_encoded['n_informative'] = test_pd_encoded.n_informative.astype(float)\n",
    "\n",
    "\n",
    "#test_pd_encoded.head()#\n",
    "randomseed = np.random.seed(1)\n",
    "scaler = pre.StandardScaler()\n",
    "#train_pd_encoded_l1 = pre.normalize(train_pd_encoded,norm=\"l1\")\n",
    "#train_pd_encoded_l2 = pre.normalize(train_pd_encoded,norm=\"l2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#mlp =  MLPRegressor(\n",
    "#    hidden_layer_sizes=(10,),  activation='relu', solver='adam', alpha=0.001, batch_size='auto',\n",
    "#    learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=5000, shuffle=True,\n",
    "#    random_state=9, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True,\n",
    "#    early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#lbfgs\n",
    "mlp = MLPRegressor(solver='lbfgs', \n",
    "                   activation='relu',\n",
    "                   hidden_layer_sizes=50, \n",
    "                   max_iter=1000,\n",
    "                   learning_rate='constant', \n",
    "                   learning_rate_init=0.01,\n",
    "                   alpha=0.01,\n",
    "                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                         int64\n",
       "l1_ratio                 float64\n",
       "alpha                    float64\n",
       "max_iter                 float64\n",
       "random_state             float64\n",
       "n_jobs                  category\n",
       "n_samples               category\n",
       "n_features               float64\n",
       "n_classes                float64\n",
       "n_clusters_per_class    category\n",
       "n_informative           category\n",
       "flip_y                   float64\n",
       "scale                    float64\n",
       "time                     float64\n",
       "penalty_elasticnet         uint8\n",
       "penalty_l1                 uint8\n",
       "penalty_l2                 uint8\n",
       "penalty_none               uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.999991\n",
      "Testing predicted score: 0.792892\n",
      "Final Prediction  score: 1.000000\n"
     ]
    }
   ],
   "source": [
    "#model train test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_before_train, y_before_train,\n",
    "                                                    test_size=0.25, random_state=0)\n",
    "#scale\n",
    "X_train_scaled = scaler.fit(X_train).transform(X_train)\n",
    "X_test_scaled = scaler.fit(X_test).transform(X_test)\n",
    "\n",
    "X_train_normalized_l1 = pre.normalize(X_train_scaled,norm=\"l2\")\n",
    "X_test_normalized_l1 = pre.normalize(X_test_scaled,norm=\"l2\")\n",
    "mlp.fit(X_train_normalized_l1,y_train)\n",
    "\n",
    "#mlp.fit(X_train_scaled,y_train)\n",
    "\n",
    "print(\"Training set score: %f\" % mlp.score(X_train_normalized_l1, y_train))\n",
    "print(\"Testing predicted score: %f\" % mlp.score(X_test_normalized_l1, y_test))\n",
    "#\n",
    "y_predicted = mlp.predict(x_to_be_preicted)\n",
    "\n",
    "print(\"Final Prediction  score: %f\" % mlp.score(x_to_be_preicted, y_predicted))\n",
    "#print(\"Testing predicted score: %f\" % mlp.score(X_test_scaled, y_predicted))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predicted has some -ve values, so use the mean values\n",
    "final_predict_df = pd.DataFrame({'time' : (y_predicted)})\n",
    "\n",
    "predicted_mean = y_predicted.mean()\n",
    "final_predict_df[final_predict_df<0] = predicted_mean\n",
    "\n",
    "final_predict_df.to_csv('/Users/soonam/Desktop/HKUST/Courses/MSBD5001/Project/Kaggle/submit10-copy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
